{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5ea4773-2ac7-4a87-81e8-95d4434985e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error # for model evaluation metrics\n",
    "from sklearn import svm,metrics,datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6604afb9-add0-4541-a0b6-97f237be479a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX</th>\n",
       "      <th>aY</th>\n",
       "      <th>aZ</th>\n",
       "      <th>rX</th>\n",
       "      <th>rY</th>\n",
       "      <th>rZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.58</td>\n",
       "      <td>2.06</td>\n",
       "      <td>7.71</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.66</td>\n",
       "      <td>2.05</td>\n",
       "      <td>7.91</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.71</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>13.27</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.63</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>17.72</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.00</td>\n",
       "      <td>1.13</td>\n",
       "      <td>11.60</td>\n",
       "      <td>-5.37</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>-2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>4.97</td>\n",
       "      <td>-3.61</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.02</td>\n",
       "      <td>-3.53</td>\n",
       "      <td>1.07</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.14</td>\n",
       "      <td>-2.28</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-3.45</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>3.03</td>\n",
       "      <td>6.79</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.62</td>\n",
       "      <td>4.38</td>\n",
       "      <td>24.15</td>\n",
       "      <td>4.42</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.33</td>\n",
       "      <td>2.76</td>\n",
       "      <td>14.72</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.84</td>\n",
       "      <td>2.97</td>\n",
       "      <td>8.99</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.93</td>\n",
       "      <td>3.01</td>\n",
       "      <td>9.02</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.50</td>\n",
       "      <td>2.84</td>\n",
       "      <td>8.81</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.97</td>\n",
       "      <td>3.14</td>\n",
       "      <td>9.26</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      aX    aY     aZ    rX    rY    rZ\n",
       "0   1.58  2.06   7.71  0.61  0.31  0.26\n",
       "1   0.66  2.05   7.91  0.37  0.79  1.96\n",
       "2  -3.71 -0.35  13.27  0.41  1.41  1.30\n",
       "3  -5.63 -0.81  17.72 -2.37  1.20 -1.42\n",
       "4  -2.00  1.13  11.60 -5.37 -1.16 -2.51\n",
       "5  -0.07 -1.00   4.97 -3.61  1.29 -0.54\n",
       "6   0.02 -3.53   1.07 -0.43  0.33 -0.21\n",
       "7  -2.14 -2.28  -1.52  1.80  0.33  0.38\n",
       "8  -3.45 -1.66   3.03  6.79  0.32 -1.21\n",
       "9  -2.62  4.38  24.15  4.42  0.47 -0.52\n",
       "10 -1.33  2.76  14.72  0.28 -0.13 -0.02\n",
       "11 -1.84  2.97   8.99 -0.20 -0.34  0.28\n",
       "12 -1.93  3.01   9.02 -0.36 -0.44  0.18\n",
       "13 -1.50  2.84   8.81  0.05 -0.16  0.18\n",
       "14 -0.97  3.14   9.26 -0.18  0.18 -0.04"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDir = \".\\spells\"\n",
    "pd.options.display.max_columns=50\n",
    "\n",
    "df=pd.read_csv(dataDir + '\\\\lumos\\Lumos1.csv' , encoding='utf-8')\n",
    "\n",
    "data = []\n",
    "#Read all data from csv file in same directory (same spell)\n",
    "\n",
    "for folder in os.listdir(dataDir):\n",
    "    if str(folder) != 'class_testing':\n",
    "        for filename in os.listdir(dataDir + '\\\\' + folder):\n",
    "            f = os.path.join(dataDir + '\\\\' + folder, filename)\n",
    "            if os.path.isfile(f):\n",
    "                #File\n",
    "                with open(f, 'r') as f:\n",
    "                    # Use the csv reader to read the file\n",
    "                    reader = csv.reader(f)\n",
    "                    next(reader)\n",
    "                    # Store the data in a list\n",
    "                    data.append(list(reader))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f1bd58e-e3e9-48d8-96b6-c084173b17ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x172ed7763b0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "arr = np.array(data[0], dtype=float)\n",
    "arr_min = arr.min()\n",
    "arr_max = arr.max()\n",
    "arr_norm = (arr - arr_min) / (arr_max - arr_min)\n",
    "plt.imshow(arr_norm,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6b19ddb-ff56-41e4-82f3-73beb65ce43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest length:  51\n"
     ]
    }
   ],
   "source": [
    "#Find longest vector\n",
    "longest_len = max([len(vector) for vector in data])\n",
    "print(\"Longest length: \", longest_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b24d0f3-cb02-47ec-8b55-77e890a1500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of sequences:  18\n"
     ]
    }
   ],
   "source": [
    "#Find average length of vectors\n",
    "avg_len = int(sum([len(vector) for vector in data])/len(data))\n",
    "print(\"Average length of sequences: \", avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "87a29ebc-d513-48d2-8402-d35f8af88330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['1.58', '2.06', '7.71', '0.61', '0.31', '0.26'],\n",
       "        ['0.66', '2.05', '7.91', '0.37', '0.79', '1.96'],\n",
       "        ['-3.71', '-0.35', '13.27', '0.41', '1.41', '1.3'],\n",
       "        ...,\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0']],\n",
       "\n",
       "       [['0.59', '1.43', '7.96', '-0.43', '0.35', '0.17'],\n",
       "        ['-1.04', '0.89', '8.66', '0.38', '0.04', '1.18'],\n",
       "        ['-1.24', '0.78', '9.95', '0.26', '0.15', '0.36'],\n",
       "        ...,\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0']],\n",
       "\n",
       "       [['-0.64', '0.53', '8.48', '-0.5', '0.35', '0.2'],\n",
       "        ['-0.7', '1.63', '8.52', '0.19', '0.24', '1.01'],\n",
       "        ['-3.09', '0.68', '10.98', '-0.04', '0.66', '0.67'],\n",
       "        ...,\n",
       "        ['-3.7', '1.38', '8.97', '0.77', '-0.63', '-0.76'],\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0']],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [['-0.2', '1.31', '10.76', '-0.67', '0.51', '0.56'],\n",
       "        ['-0.82', '1.02', '9.94', '0.62', '0.32', '0.58'],\n",
       "        ['-2.14', '1.14', '10.19', '0.18', '0.7', '0.85'],\n",
       "        ...,\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0']],\n",
       "\n",
       "       [['2.78', '2.62', '7.95', '-0.1', '0.57', '0.65'],\n",
       "        ['0.37', '2.82', '9.58', '-0.6', '0.12', '2.08'],\n",
       "        ['-3.88', '0.43', '9.96', '-1.58', '0.71', '2.48'],\n",
       "        ...,\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0'],\n",
       "        ['0.0', '0.0', '0.0', '0.0', '0.0', '0.0']],\n",
       "\n",
       "       [['1.39', '2.74', '8.19', '0.43', '1.62', '1.6'],\n",
       "        ['-2.0', '2.14', '8.27', '-1.77', '2.42', '2.93'],\n",
       "        ['-3.99', '0.94', '7.69', '-1.58', '1.62', '1.85'],\n",
       "        ...,\n",
       "        ['0.09', '-0.27', '9.77', '-0.02', '-0.02', '-0.0'],\n",
       "        ['-0.06', '-0.22', '10.26', '-0.03', '-0.02', '-0.01'],\n",
       "        ['0.09', '-0.28', '9.74', '-0.02', '-0.02', '-0.0']]],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def normalizeVectors(data): \n",
    "    for vectors in data:\n",
    "        if len(vectors) < avg_len:\n",
    "            #Apply padding to vectors sequences less than max length     \n",
    "            difference = avg_len - len(vectors)\n",
    "            array = np.zeros((difference, 6))\n",
    "            list_of_arrays = array.tolist()\n",
    "            vectors.extend(list_of_arrays)\n",
    "        elif len(vectors) > avg_len:\n",
    "            #Cut last vectors in sequence to make them average size\n",
    "            difference = len(vectors) - avg_len\n",
    "            for i in range(difference): vectors.pop()\n",
    "\n",
    "normalizeVectors(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "38a97a6d-cc52-40cd-badf-9fe2040843da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (180, 6)\n",
      "Labels shape:  (10, 1)\n"
     ]
    }
   ],
   "source": [
    "#Additional parameters\n",
    "batch_size = 10              #length of files\n",
    "sequence_length = avg_len    #Amount of data vectors in a file\n",
    "num_features = 6             #Length of data vectors\n",
    "num_classes = 2\n",
    "\n",
    "data = np.array(data,dtype=float)\n",
    "\n",
    "# (x,y,z) x secuencias (archivos) con y vectores de z características\n",
    "print(\"Data shape: \", data.shape)\n",
    "\n",
    "#Etiquetas\n",
    "#Necesitamos etiquetas de dimension (x,1)\n",
    "labels = []\n",
    "for i in range(5): labels.append([0])\n",
    "for i in range(5): labels.append([1])\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Labels shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "9124ada8-a55d-4b40-9588-2057c8466048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 0.6308 - val_loss: 0.9161\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6303 - val_loss: 0.9186\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6298 - val_loss: 0.9210\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6294 - val_loss: 0.9234\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6289 - val_loss: 0.9258\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6285 - val_loss: 0.9282\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6280 - val_loss: 0.9306\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6276 - val_loss: 0.9331\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6272 - val_loss: 0.9355\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6267 - val_loss: 0.9379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c83de33fa0>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aplicamos escalado min max\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#MinMaxScaler solo toma arrays de 1 o 2 dimensiones por lo que tenemos que transformar los datos\n",
    "X_reshaped = data.reshape(-1,num_features)\n",
    "X_scaled=scaler.fit_transform(X_reshaped)\n",
    "X_scaled = X_scaled.reshape(batch_size, sequence_length, num_features)\n",
    "\n",
    "#Separamos en conjuntos de training y de test\n",
    "train_data, test_data = train_test_split(X_scaled, test_size=0.3, shuffle=False)\n",
    "#Ahora tenemos que crear los dos conjuntos de labels\n",
    "labels_train = labels[0:7] \n",
    "labels_test = labels[7:10]\n",
    "\n",
    "#Estructura de la red neuronal\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(sequence_length, 6)))\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "\n",
    "model.fit(train_data, labels_train, epochs=10, batch_size=batch_size, validation_data=(test_data, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5151cf4c-c919-4822-9844-36dfefa74714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 26 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001C843FEF7F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "\n",
      "-------------------- Model Summary --------------------\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 18, 1)             7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7\n",
      "Trainable params: 7\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "-------------------- Weights and Biases --------------------\n",
      "Note, the last parameter in each layer is bias while the rest are weights\n",
      "\n",
      "dense_20\n",
      "   [[-0.72160614]\n",
      " [ 0.5370714 ]\n",
      " [ 0.04343458]\n",
      " [ 0.16806464]\n",
      " [-0.66382843]\n",
      " [-0.09615263]]\n",
      "   [-0.00997212]\n"
     ]
    }
   ],
   "source": [
    "##### Step 7 - Use model to make predictions\n",
    "# Predict the result on training data\n",
    "pred_train = model.predict(train_data)\n",
    "# Predict the result on test data\n",
    "pred_test = model.predict(test_data)\n",
    "\n",
    "\n",
    "##### Step 8 - Model Performance Summary\n",
    "print(\"\")\n",
    "print('-------------------- Model Summary --------------------')\n",
    "model.summary() # print model summary\n",
    "print(\"\")\n",
    "print('-------------------- Weights and Biases --------------------')\n",
    "print(\"Note, the last parameter in each layer is bias while the rest are weights\")\n",
    "print(\"\")\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n",
    "    for item in layer.get_weights():\n",
    "        print(\"  \", item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "148d59cb-8ff6-47cd-ba98-7f3791d69860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 2.020e+00  1.470e+00  9.600e+00  1.800e-01  0.000e+00  3.100e-01]\n",
      "  [ 2.040e+00  1.530e+00  8.620e+00  1.000e-02  5.000e-02  4.300e-01]\n",
      "  [ 7.600e-01  1.160e+00  1.012e+01  4.000e-01  2.500e-01  5.500e-01]\n",
      "  [ 4.000e-02  1.070e+00  1.292e+01  8.000e-02  8.500e-01  8.300e-01]\n",
      "  [-2.550e+00  4.800e-01  1.675e+01 -3.010e+00  6.700e-01 -1.280e+00]\n",
      "  [ 3.000e-02  6.300e-01  8.040e+00 -4.460e+00  1.000e-01 -1.240e+00]\n",
      "  [ 2.630e+00 -2.640e+00  1.280e+00 -2.400e+00  2.400e-01 -9.000e-02]\n",
      "  [-4.300e-01 -5.470e+00 -5.000e-02 -3.200e-01  5.000e-01  2.400e-01]\n",
      "  [-2.550e+00 -5.070e+00  1.310e+00  2.250e+00  8.800e-01 -7.300e-01]\n",
      "  [-2.710e+00 -6.600e-01  4.640e+00  5.660e+00  1.750e+00 -2.000e+00]\n",
      "  [ 4.350e+00  6.340e+00  1.957e+01  3.320e+00  4.600e-01 -2.280e+00]\n",
      "  [ 2.260e+00  7.200e-01  1.020e+01 -5.700e-01 -7.000e-02  4.500e-01]\n",
      "  [-2.500e-01  9.000e-02  1.025e+01 -3.400e-01  4.000e-02  4.200e-01]\n",
      "  [ 4.100e-01  6.900e-01  8.750e+00 -9.000e-02  2.000e-02  2.000e-02]\n",
      "  [ 4.600e-01  5.900e-01  1.079e+01 -1.700e-01 -1.300e-01 -1.000e-01]\n",
      "  [ 2.720e+00  2.430e+00  7.450e+00  2.900e-01  1.600e-01  5.000e-02]\n",
      "  [ 1.730e+00  2.720e+00  8.130e+00  2.000e-02  7.400e-01  1.050e+00]\n",
      "  [-2.000e-02  2.280e+00  9.540e+00  2.000e-01  7.500e-01  7.500e-01]]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[[0]\n",
      "  [0]\n",
      "  [1]\n",
      "  [1]\n",
      "  [1]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]\n",
      "  [1]\n",
      "  [1]\n",
      "  [0]\n",
      "  [1]\n",
      "  [1]\n",
      "  [1]\n",
      "  [0]\n",
      "  [0]\n",
      "  [1]]]\n",
      "9 9\n"
     ]
    }
   ],
   "source": [
    "#Probamos ejemplo de prueba\n",
    "example_data = []\n",
    "\n",
    "with open(dataDir + '\\\\testing\\\\test1.csv', 'r') as f:\n",
    "    # Use the csv reader to read the file\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    # Store the data in a list\n",
    "    example_data.append(list(reader))\n",
    "\n",
    "normalizeVectors(example_data)\n",
    "\n",
    "example_data = np.array(example_data,dtype=float)\n",
    "\n",
    "print(example_data)\n",
    "prediction = model.predict(example_data)\n",
    "prediction = np.where(prediction > 0.5, 1, 0)\n",
    "print(prediction)\n",
    "\n",
    "votes_0 = 0\n",
    "votes_1 = 0\n",
    "\n",
    "for vector in prediction[0]:\n",
    "    if vector[0] == 0: votes_0 +=1\n",
    "    else: votes_1 +=1\n",
    "print(votes_0, votes_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc977631-5ba6-40a4-bd3f-40f9704eaebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea7921f-6025-4d8f-847c-bfb766529f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
